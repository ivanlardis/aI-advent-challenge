# AI Advent Challenge

## Задание 1
- Формулировка: реализовать простого агента, который отвечает на вопросы и выводит это в интерфейсе (простой чат, отправка/получение запросов через HTTP-клиент).
- Реализация: Chainlit UI + LangChain цепочка, проксирующая запросы в OpenRouter.
- Результат: агент принимает запрос и корректно вызывает инструмент (OpenRouter), ответ отображается в чате.
- Формат сдачи: код + демонстрационное видео (запуск `chainlit run ...` и работа через http://localhost:8000).
- Рекомендуемый префикс коммита: `chore: AI Advent Challenge 1 – ...`.

## Задание 2
- Формулировка: научиться задавать формат результата для возвращения от LLM, продемонстрировать умение парсить структурированные ответы.
- Реализация: использование `JsonOutputParser` из LangChain для получения структурированного JSON-ответа. Пример использования: анализ настроения текста.
- Результат: LLM возвращает ответ в формате JSON с полями `sentiment`, `confidence`, `keywords`, `summary`. JSON автоматически парсится и валидируется, результат отображается в красивом формате с сырым JSON.
- Технические детали:
  - `JsonOutputParser` автоматически добавляет `{format_instructions}` в промпт
  - Автоматическая валидация и парсинг JSON
  - Обработка ошибок при невалидном формате
- Формат сдачи: код + демонстрация работы (отправка текста и получение структурированного анализа).
- Рекомендуемый префикс коммита: `feat: AI Advent Challenge 2 – ...`.

## Задание 3
- Формулировка: реализовать конверсационного агента, который собирает информацию через диалог и сам определяет момент завершения.
- Реализация: бот-нутрициолог для расчёта БЖУ с автоматическим завершением диалога.
- Результат:
  - Модель задаёт 5 вопросов (рост, вес, возраст, пол, уровень активности)
  - Собирает ответы через историю диалога
  - Автоматически завершает диалог через флаг `is_complete=true`
  - Рассчитывает BMR, калорийность и БЖУ (30% белки, 30% жиры, 40% углеводы)
  - Возвращает расчёт в формате Markdown
- Технические детали:
  - JSON-структура: `{is_complete, message, collected_info, final_document}`
  - История сообщений: простой список с `HumanMessage` и `AIMessage`
  - JsonOutputParser для валидации и парсинга ответов
  - Отключены размышления модели (`reasoning_effort: disabled`)
  - Рекомендуемая модель: `x-ai/grok-4.1-fast:free`
- Формат сдачи: код + демонстрационное видео.
- Префикс коммита: `feat: AI Advent Challenge 3 – ...`

## Задание 4
- Формулировка: исследовать влияние system prompt на поведение агента, сохраняя историю диалога при смене промпта.
- Реализация: интерфейс для смены system prompt с 4 предустановленными ролями + сохранение истории сообщений.
- Результат:
  - UI для выбора роли агента (⚙️ в верхнем правом углу Chainlit)
  - 4 предустановленные роли:
    - **nutritionist** — нутрициолог для расчёта БЖУ (строгий формат, JSON-ответы)
    - **strict_teacher** — строгий преподаватель Python (краткие ответы, наводящие вопросы)
    - **friendly_mentor** — дружелюбный наставник (простые объяснения, много примеров)
    - **code_reviewer** — критичный код-ревьюер (детальный анализ, указание проблем)
  - История сообщений сохраняется при смене роли
  - System prompt применяется динамически из user session
- План тестирования:
  1. Выбрать тему (например: "объяснение рекурсии в Python")
  2. Начать диалог с `strict_teacher` (5-10 сообщений)
  3. Зафиксировать стиль ответов (тон, структура, глубина)
  4. Переключиться на `friendly_mentor`
  5. Продолжить диалог на ту же тему
  6. Сравнить различия в стиле, подаче информации, вопросах
  7. Повторить с другими ролями для разных сценариев
- Технические детали:
  - `cl.ChatSettings` с `cl.input_widget.Select` для UI
  - `@cl.on_settings_update` для обработки смены роли
  - Динамическая подстановка system prompt через `cl.user_session.get()`
  - История сохраняется в сессии независимо от system prompt
- Формат сдачи: код + демонстрация (видео с переключением ролей и сравнением ответов).
- Префикс коммита: `feat: AI Advent Challenge 4 – ...`
